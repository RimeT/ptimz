{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3187108d-a9a2-47b2-9707-2ce81d82062f",
   "metadata": {},
   "source": [
    "# Transfer a reset/efficientnet to resunet/efficientunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03930849-bff9-4261-b924-7f8d0b082fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from torch import nn\n",
    "from ptimz.model_zoo import ResNet, UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411f27ad-8469-491b-83d8-e6f986c941fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_chans = 2 # Assume we have T1-w T2-w as input\n",
    "out_chans = 8 # We want to segment 8 types of objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82b92df-e19e-4101-8c27-53d8fc16ba2d",
   "metadata": {},
   "source": [
    "## We need to split backbone(resnet/efficientnet) into groups of encoders\n",
    "### efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db63b083-f264-4fac-bac9-98cf19c17ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier(fc layer) is not required\n",
    "backbone = timm.create_model('efficientnet_b0', in_chans=in_chans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30344ef0-1112-43b8-b459-4ce955e7fbda",
   "metadata": {},
   "source": [
    "**Let's construct a 2d image input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90c947e-b92d-4eaf-8913-3b2b5f88c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_2d = torch.rand(size=(1, in_chans, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e55e68-d2c2-451d-87de-956b6f2002ce",
   "metadata": {},
   "source": [
    "**Efficientnet consists of stem -> blocks x N -> featrue map**  \n",
    "**Let's go through efficientnet convolution blocks. Record output channels of each block output** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee44517a-282a-4de1-b847-90e07b113d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input torch.Size([1, 2, 224, 224])\n",
      "stem torch.Size([1, 32, 112, 112]) channels 32\n",
      "block 0 torch.Size([1, 16, 112, 112]) channles 16 ratio 0.5\n",
      "block 1 torch.Size([1, 24, 56, 56]) channles 24 ratio 0.25\n",
      "block 2 torch.Size([1, 40, 28, 28]) channles 40 ratio 0.125\n",
      "block 3 torch.Size([1, 80, 14, 14]) channles 80 ratio 0.0625\n",
      "block 4 torch.Size([1, 112, 14, 14]) channles 112 ratio 0.0625\n",
      "block 5 torch.Size([1, 192, 7, 7]) channles 192 ratio 0.03125\n",
      "block 6 torch.Size([1, 320, 7, 7]) channles 320 ratio 0.03125\n"
     ]
    }
   ],
   "source": [
    "efficientnet_stem = nn.Sequential(backbone.conv_stem, backbone.bn1, backbone.act1)\n",
    "with torch.no_grad():\n",
    "    stemout = efficientnet_stem(input_2d)\n",
    "print(f\"input {input_2d.shape}\")\n",
    "print(f\"stem {stemout.shape} channels {stemout.shape[1]}\") # 32 channels, down sample to 1/2\n",
    "\n",
    "# go through efficientnet blocks\n",
    "blkout = stemout\n",
    "with torch.no_grad():\n",
    "    for block_id, blk in enumerate(backbone.blocks):\n",
    "        blkout = blk(blkout)\n",
    "        shape = blkout.shape\n",
    "        print(f\"block {block_id} {shape} channles {shape[1]} ratio {shape[-1]/224}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f6b9a-e502-4471-afa7-cb3227879698",
   "metadata": {},
   "source": [
    "## Let's construct efficientunet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5753e7-b59b-401d-bd7c-08b9e22c3a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = timm.create_model('efficientnet_b0', in_chans=in_chans)\n",
    "\n",
    "# Load backbone state_dict here\n",
    "# checkpoint = torch.load(\"backbone.pth.tar\", map_location='cpu')\n",
    "# backbone.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n",
    "efficientnet_stem = nn.Sequential(backbone.conv_stem, backbone.bn1, backbone.act1)\n",
    "unet_encoders = [nn.Sequential(backbone.conv_stem, backbone.bn1, backbone.act1, backbone.blocks[0]),\n",
    "                backbone.blocks[1],\n",
    "                backbone.blocks[2],\n",
    "                nn.Sequential(*backbone.blocks[3:5]),\n",
    "                nn.Sequential(*backbone.blocks[5:])]\n",
    "# ptimz UNet config\n",
    "extra = dict(num_channels=[16, 24, 40, 112, 320], # output channels of each encoder\n",
    "             nclasses=out_chans) # classes to segment\n",
    "conv_cfg = dict(type='Conv2d')\n",
    "norm_cfg = dict(type='BN2d', requires_grad=True)\n",
    "efficientunet = UNet(extra, unet_encoders, conv_cfg=conv_cfg, norm_cfg=norm_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a693f1-53b0-4dc1-87f3-2c66aa4ac102",
   "metadata": {},
   "source": [
    "### EfficientUnet prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c0972a-73cb-47f9-b6ae-343752c9848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_2d = efficientunet(input_2d)\n",
    "print(output_2d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3918b5e2-0d6a-4ee8-a19f-bf5740f4be0a",
   "metadata": {},
   "source": [
    "### Resunet with Resnet50 as backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab9491b-0e29-47b6-9a7a-d4476658f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_3d = torch.rand(size=(1, in_chans, 128, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b16274d3-f70a-404a-b586-ec54fab3bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_cfg = dict(type='Conv3d')\n",
    "norm_cfg = dict(type='BN3d', requires_grad=True)\n",
    "backbone = ResNet(50, in_channels=in_chans, deep_stem=True,\n",
    "                 first_stride=1, conv_cfg=conv_cfg, norm_cfg=norm_cfg)\n",
    "\n",
    "# load backbone pretrained weights here\n",
    "# backbone.load_state_dict(...)\n",
    "\n",
    "unet_encoders = [backbone.stem, nn.Sequential(backbone.maxpool, getattr(backbone, backbone.res_layers[0]))] + [\n",
    "                 getattr(backbone, x) for x in backbone.res_layers[1:]]\n",
    "\n",
    "extra = dict(num_channels=[64, 256, 512, 1024, 2048],\n",
    "             nclasses=out_chans)\n",
    "resunet = UNet(extra, unet_encoders, conv_cfg=conv_cfg, norm_cfg=norm_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ff7d90-23be-4939-b7d8-3031d6ffe188",
   "metadata": {},
   "source": [
    "### Resunet prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d236e2-d61b-4b35-90bf-8045d421af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 128, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_3d = resunet(input_3d)\n",
    "print(output_3d.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
